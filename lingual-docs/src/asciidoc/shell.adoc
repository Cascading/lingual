[id="shell"]
## Lingual Shell

Lingual Shell is an interactive SQL command shell.

Lingual Shell expects to find a catalog configuration that defines available Schemas and Tables in the current
directory for the specified platform.

The catalog information is created and maintained by the <<catalog,Catalog>> utility. By default, the catalog utility
will create a directory named `.lingual` in the current directory with additional directories and files.

### Setting Job Properties

After using the <<catalog,Catalog>> to initialize a new catalog (in the `.lingual` directory),
a `.lingual/config/default.properties` file will be created. Edit this file to add new properties to be used by the
underlying platform. In the case of Hadoop, the number of reducers to use for all jobs could be set here.

The `LINGUAL_CONFIG` environment variable may also be used to provide _bootstrap_ properties to Shell.

See the notes on <<hadoop,Hadoop>> for more information on setting properties.

### CLI Usage

Catalog is invoked from the command line via:

    lingual shell [switches]*

To start the shell for running queries on Apache Hadoop:

    lingual shell --platform hadoop

### CLI Options Reference

[width="100%",cols="<30m,<40d",frame="topbot",options="header"]
|===
| switch               | description
|                      |
| --platform [name]    | use the named platform
|                      |
| --schema [name]      | name of the default schema (same as `set schema _name_`)
|                      |
| --schemas [uri,...]  | root path for each schema to use, will use base directory as schema name. sub-directories will be treated as tables
|                      |
| --sql [file]         | file with SQL commands to execute
|                      |
| --resultPath [dir]   | where to store temporary result sets
| --flowPlanPath [dir] | where to write out the Cascading planner DOT file for debugging
| --sqlPlanPath [dir ] | where to write out the Optiq planner plan file for debugging
|===

### Configuration

See <<hadoop.html,Configuring Apache Hadoop>> for using with a Apache Hadoop cluster.

<<top>>