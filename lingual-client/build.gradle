/*
 * Copyright (c) 2007-2013 Concurrent, Inc. All Rights Reserved.
 *
 * Project and contact information: http://www.cascading.org/
 *
 * This file is part of the Cascading project.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import org.apache.tools.ant.filters.ReplaceTokens

apply plugin: 'application'

evaluationDependsOn( ':lingual-local' )
evaluationDependsOn( ':lingual-hadoop' )

dependencies {

  providedCompile project( ':lingual-core' ) // provided by platform/jdbc drivers

  compile group: 'net.sf.jopt-simple', name: 'jopt-simple', version: joptVersion
  compile group: 'sqlline', name: 'sqlline', version: sqllineVersion
  compile group: 'org.apache.ivy', name: 'ivy', version: ivyVersion

  runtime group: 'jline', name: 'jline', version: jlineVersion

  providedCompile group: 'org.slf4j', name: 'slf4j-api', version: slf4jVersion

  testCompile project( ':lingual-core' ) // provided by platform/jdbc drivers
}

jar {
  ext.finalName = jar.archivePath
  classifier = 'unshaded'
}

jar << {
  project.ant {
    taskdef( name: "jarjar", classname: "com.tonicsystems.jarjar.JarJarTask", classpath: configurations.jarjar.asPath )

    jarjar( jarfile: finalName ) {
      zipfileset( src: jar.archivePath )

      neverIncludePackages.each { omitClass ->
        zap pattern: omitClass
      }
      unshadeableDependencies.each { retainClass ->
        rule pattern: retainClass, result: "@0"
      }
      shadeableDependencies.each { shadeClass ->
        rule pattern: shadeClass, result: "${shadePackagePrefix}@0"
      }
    }
  }
}

task assembleDist( dependsOn: jar ) {
  dependsOn << project( ":lingual-local" ).tasks[ "fatJar" ]
  dependsOn << project( ":lingual-hadoop" ).tasks[ "hadoopJar" ]
  dependsOn << project( ":lingual-hadoop" ).tasks[ "fatJar" ]

  ext.distDir = file( "${buildDir}/dist" )
}

assembleDist << {

  distDir.delete();
  distDir.mkdir();

  copy {
    into "${distDir}/lib"
    from configurations.runtime
    from jar.finalName
  }

  copy {
    into "${distDir}/platform/local"
    from project( ":lingual-local" ).fatJar
  }

  copy {
    into "${distDir}/platform/hadoop"
    from project( ":lingual-hadoop" ).fatJar
  }

  copy {
    into distDir
    from( 'src/dist/etc/' ) {
      filter( ReplaceTokens, tokens: [
              'releaseVersion': "${releaseVersion}".toString()
      ] )
    }
  }

  copy {
    fileMode = 0755
    into "${distDir}/bin/"
    from( 'src/dist/bin/' ) {
      rename '\\.sh', ''
      filter( ReplaceTokens, tokens: [
              'location': project.s3Bucket.toString(),
              'majorVersion': majorVersion.toString()
      ] )
    }
  }
}

task packageDist( type: Tar, dependsOn: assembleDist ) {
  description = "package current build, does not run tests"

  destinationDir = file( s3UploadArtifacts.source )
  compression = "GZIP"

  into( baseName ) {
    from assembleDist.distDir
  }

  s3UploadArtifacts.dependsOn packageDist
}

packageDist << {

  copy {
    from( 'src/dist/util/install-lingual-client.sh' ) {
      filter( ReplaceTokens, tokens: [
              'location': project.s3Bucket.toString(),
              'majorVersion': majorVersion.toString()
      ] )
    }
    into s3UploadArtifacts.source
  }

  file( "${s3UploadArtifacts.source}/latest.txt" ).write( "http://${s3UploadArtifacts.destination}${archiveName}" )
}

uploadArchives.enabled = false

platformTest.enabled = false

